{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca0f84f3-763c-4c46-81b2-ce257637a53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LassoCV\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd72c16c-3164-4d61-bd06-0327fbfb0838",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adef6b23-46cc-48ad-aee1-69e235ab6eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_peak_hour</th>\n",
       "      <th>is_night_hour</th>\n",
       "      <th>PU_is_midtown</th>\n",
       "      <th>PU_is_uptown</th>\n",
       "      <th>PU_is_downtown</th>\n",
       "      <th>DO_is_midtown</th>\n",
       "      <th>DO_is_uptown</th>\n",
       "      <th>DO_is_downtown</th>\n",
       "      <th>vendor_2</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>tip_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.402384</td>\n",
       "      <td>-0.161779</td>\n",
       "      <td>-0.254309</td>\n",
       "      <td>-0.902054</td>\n",
       "      <td>-0.265522</td>\n",
       "      <td>0.040308</td>\n",
       "      <td>0.271461</td>\n",
       "      <td>-0.310566</td>\n",
       "      <td>1.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.402384</td>\n",
       "      <td>-0.370128</td>\n",
       "      <td>-0.379366</td>\n",
       "      <td>-0.340178</td>\n",
       "      <td>-0.265522</td>\n",
       "      <td>0.040308</td>\n",
       "      <td>0.271461</td>\n",
       "      <td>-0.310566</td>\n",
       "      <td>3.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.402384</td>\n",
       "      <td>-0.374657</td>\n",
       "      <td>-0.337681</td>\n",
       "      <td>0.502637</td>\n",
       "      <td>-0.265522</td>\n",
       "      <td>0.040308</td>\n",
       "      <td>0.271461</td>\n",
       "      <td>-0.310566</td>\n",
       "      <td>2.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.402384</td>\n",
       "      <td>3.189915</td>\n",
       "      <td>3.068634</td>\n",
       "      <td>0.502637</td>\n",
       "      <td>-0.265522</td>\n",
       "      <td>0.040308</td>\n",
       "      <td>0.271461</td>\n",
       "      <td>-0.310566</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.712355</td>\n",
       "      <td>-0.626034</td>\n",
       "      <td>-0.796223</td>\n",
       "      <td>-0.340178</td>\n",
       "      <td>-0.265522</td>\n",
       "      <td>0.040308</td>\n",
       "      <td>0.271461</td>\n",
       "      <td>-0.310566</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.402384</td>\n",
       "      <td>-0.247836</td>\n",
       "      <td>-0.379366</td>\n",
       "      <td>-0.902054</td>\n",
       "      <td>-0.265522</td>\n",
       "      <td>0.040308</td>\n",
       "      <td>0.271461</td>\n",
       "      <td>-0.310566</td>\n",
       "      <td>3.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.402384</td>\n",
       "      <td>-0.034959</td>\n",
       "      <td>0.162547</td>\n",
       "      <td>-0.902054</td>\n",
       "      <td>-0.265522</td>\n",
       "      <td>0.040308</td>\n",
       "      <td>0.271461</td>\n",
       "      <td>-0.310566</td>\n",
       "      <td>5.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.402384</td>\n",
       "      <td>-0.433538</td>\n",
       "      <td>-0.462738</td>\n",
       "      <td>-0.902054</td>\n",
       "      <td>-0.265522</td>\n",
       "      <td>0.040308</td>\n",
       "      <td>0.271461</td>\n",
       "      <td>-0.310566</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.402384</td>\n",
       "      <td>-0.528654</td>\n",
       "      <td>-0.629480</td>\n",
       "      <td>-0.902054</td>\n",
       "      <td>-0.265522</td>\n",
       "      <td>0.040308</td>\n",
       "      <td>0.271461</td>\n",
       "      <td>-0.310566</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.402384</td>\n",
       "      <td>3.076682</td>\n",
       "      <td>3.068634</td>\n",
       "      <td>4.014365</td>\n",
       "      <td>3.078956</td>\n",
       "      <td>0.040308</td>\n",
       "      <td>0.271461</td>\n",
       "      <td>3.219929</td>\n",
       "      <td>21.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       is_peak_hour  is_night_hour  PU_is_midtown  PU_is_uptown  \\\n",
       "0                 0              0              0             0   \n",
       "1                 0              1              0             1   \n",
       "2                 1              0              0             0   \n",
       "3                 0              0              0             0   \n",
       "4                 0              1              0             0   \n",
       "...             ...            ...            ...           ...   \n",
       "29995             0              0              0             0   \n",
       "29996             0              0              0             0   \n",
       "29997             0              0              0             0   \n",
       "29998             0              0              0             0   \n",
       "29999             1              0              0             0   \n",
       "\n",
       "       PU_is_downtown  DO_is_midtown  DO_is_uptown  DO_is_downtown  vendor_2  \\\n",
       "0                   0              0             0               1         1   \n",
       "1                   0              1             0               0         1   \n",
       "2                   1              0             0               0         1   \n",
       "3                   0              0             0               0         0   \n",
       "4                   0              0             1               0         1   \n",
       "...               ...            ...           ...             ...       ...   \n",
       "29995               0              0             0               1         1   \n",
       "29996               1              1             0               0         1   \n",
       "29997               0              0             0               1         1   \n",
       "29998               1              0             0               0         1   \n",
       "29999               0              1             0               0         0   \n",
       "\n",
       "       is_weekend  passenger_count  trip_distance  fare_amount     extra  \\\n",
       "0               1        -0.402384      -0.161779    -0.254309 -0.902054   \n",
       "1               0        -0.402384      -0.370128    -0.379366 -0.340178   \n",
       "2               0        -0.402384      -0.374657    -0.337681  0.502637   \n",
       "3               1        -0.402384       3.189915     3.068634  0.502637   \n",
       "4               0         0.712355      -0.626034    -0.796223 -0.340178   \n",
       "...           ...              ...            ...          ...       ...   \n",
       "29995           0        -0.402384      -0.247836    -0.379366 -0.902054   \n",
       "29996           0        -0.402384      -0.034959     0.162547 -0.902054   \n",
       "29997           1        -0.402384      -0.433538    -0.462738 -0.902054   \n",
       "29998           0        -0.402384      -0.528654    -0.629480 -0.902054   \n",
       "29999           0        -0.402384       3.076682     3.068634  4.014365   \n",
       "\n",
       "       tolls_amount  improvement_surcharge  congestion_surcharge  airport_fee  \\\n",
       "0         -0.265522               0.040308              0.271461    -0.310566   \n",
       "1         -0.265522               0.040308              0.271461    -0.310566   \n",
       "2         -0.265522               0.040308              0.271461    -0.310566   \n",
       "3         -0.265522               0.040308              0.271461    -0.310566   \n",
       "4         -0.265522               0.040308              0.271461    -0.310566   \n",
       "...             ...                    ...                   ...          ...   \n",
       "29995     -0.265522               0.040308              0.271461    -0.310566   \n",
       "29996     -0.265522               0.040308              0.271461    -0.310566   \n",
       "29997     -0.265522               0.040308              0.271461    -0.310566   \n",
       "29998     -0.265522               0.040308              0.271461    -0.310566   \n",
       "29999      3.078956               0.040308              0.271461     3.219929   \n",
       "\n",
       "       tip_amount  \n",
       "0            1.82  \n",
       "1            3.42  \n",
       "2            2.90  \n",
       "3            0.00  \n",
       "4            0.00  \n",
       "...           ...  \n",
       "29995        3.22  \n",
       "29996        5.04  \n",
       "29997        2.94  \n",
       "29998        1.00  \n",
       "29999       21.65  \n",
       "\n",
       "[30000 rows x 19 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load your cleaned sample\n",
    "df = pd.read_csv('combined_final_sample_new.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45bf48db-37fa-4145-bf3c-6b0ff5751db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['is_peak_hour', 'is_night_hour', 'PU_is_midtown', 'PU_is_uptown',\n",
       "       'PU_is_downtown', 'DO_is_midtown', 'DO_is_uptown', 'DO_is_downtown',\n",
       "       'vendor_2', 'is_weekend', 'passenger_count', 'trip_distance',\n",
       "       'fare_amount', 'extra', 'tolls_amount', 'improvement_surcharge',\n",
       "       'congestion_surcharge', 'airport_fee', 'tip_amount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns\n",
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff382d31-34ab-42f7-9b1b-f00c44eb8daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_peak_hour</th>\n",
       "      <th>is_night_hour</th>\n",
       "      <th>PU_is_midtown</th>\n",
       "      <th>PU_is_uptown</th>\n",
       "      <th>PU_is_downtown</th>\n",
       "      <th>DO_is_midtown</th>\n",
       "      <th>DO_is_uptown</th>\n",
       "      <th>DO_is_downtown</th>\n",
       "      <th>vendor_2</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>tip_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [is_peak_hour, is_night_hour, PU_is_midtown, PU_is_uptown, PU_is_downtown, DO_is_midtown, DO_is_uptown, DO_is_downtown, vendor_2, is_weekend, passenger_count, trip_distance, fare_amount, extra, tolls_amount, improvement_surcharge, congestion_surcharge, airport_fee, tip_amount]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e5d2c0c-8fa9-4995-8569-2be8557dcd70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    30000.000000\n",
       "mean         3.383050\n",
       "std          3.736364\n",
       "min          0.000000\n",
       "25%          1.000000\n",
       "50%          2.740000\n",
       "75%          4.200000\n",
       "max         93.000000\n",
       "Name: tip_amount, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"tip_amount\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0bc01a9-1fdf-4b96-b5e4-184d282f4052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_peak_hour</th>\n",
       "      <th>is_night_hour</th>\n",
       "      <th>PU_is_midtown</th>\n",
       "      <th>PU_is_uptown</th>\n",
       "      <th>PU_is_downtown</th>\n",
       "      <th>DO_is_midtown</th>\n",
       "      <th>DO_is_uptown</th>\n",
       "      <th>DO_is_downtown</th>\n",
       "      <th>vendor_2</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>tip_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.402384</td>\n",
       "      <td>3.189915</td>\n",
       "      <td>3.068634</td>\n",
       "      <td>0.502637</td>\n",
       "      <td>-0.265522</td>\n",
       "      <td>0.040308</td>\n",
       "      <td>0.271461</td>\n",
       "      <td>-0.310566</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.712355</td>\n",
       "      <td>-0.626034</td>\n",
       "      <td>-0.796223</td>\n",
       "      <td>-0.340178</td>\n",
       "      <td>-0.265522</td>\n",
       "      <td>0.040308</td>\n",
       "      <td>0.271461</td>\n",
       "      <td>-0.310566</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.402384</td>\n",
       "      <td>-0.512801</td>\n",
       "      <td>-0.587795</td>\n",
       "      <td>-0.340178</td>\n",
       "      <td>-0.265522</td>\n",
       "      <td>0.040308</td>\n",
       "      <td>0.271461</td>\n",
       "      <td>-0.310566</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.402384</td>\n",
       "      <td>3.214826</td>\n",
       "      <td>3.068634</td>\n",
       "      <td>-0.902054</td>\n",
       "      <td>3.078956</td>\n",
       "      <td>0.040308</td>\n",
       "      <td>0.271461</td>\n",
       "      <td>-0.310566</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.402384</td>\n",
       "      <td>-0.222925</td>\n",
       "      <td>-0.170938</td>\n",
       "      <td>-0.340178</td>\n",
       "      <td>-0.265522</td>\n",
       "      <td>0.040308</td>\n",
       "      <td>0.271461</td>\n",
       "      <td>-0.310566</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29981</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.402384</td>\n",
       "      <td>2.141378</td>\n",
       "      <td>1.829974</td>\n",
       "      <td>2.469205</td>\n",
       "      <td>-0.265522</td>\n",
       "      <td>0.040308</td>\n",
       "      <td>-3.683772</td>\n",
       "      <td>3.219929</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29985</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.402384</td>\n",
       "      <td>-0.202543</td>\n",
       "      <td>-0.295995</td>\n",
       "      <td>-0.340178</td>\n",
       "      <td>-0.265522</td>\n",
       "      <td>0.040308</td>\n",
       "      <td>0.271461</td>\n",
       "      <td>-0.310566</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29989</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.402384</td>\n",
       "      <td>1.174369</td>\n",
       "      <td>0.954575</td>\n",
       "      <td>3.171550</td>\n",
       "      <td>-0.265522</td>\n",
       "      <td>0.040308</td>\n",
       "      <td>-3.683772</td>\n",
       "      <td>3.219929</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29991</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.402384</td>\n",
       "      <td>3.121975</td>\n",
       "      <td>3.068634</td>\n",
       "      <td>1.204983</td>\n",
       "      <td>3.078956</td>\n",
       "      <td>0.040308</td>\n",
       "      <td>0.271461</td>\n",
       "      <td>3.219929</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29992</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.941833</td>\n",
       "      <td>-0.025900</td>\n",
       "      <td>0.287604</td>\n",
       "      <td>0.502637</td>\n",
       "      <td>-0.265522</td>\n",
       "      <td>0.040308</td>\n",
       "      <td>0.271461</td>\n",
       "      <td>-0.310566</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6413 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       is_peak_hour  is_night_hour  PU_is_midtown  PU_is_uptown  \\\n",
       "3                 0              0              0             0   \n",
       "4                 0              1              0             0   \n",
       "20                0              1              0             0   \n",
       "22                0              0              1             0   \n",
       "24                0              1              0             0   \n",
       "...             ...            ...            ...           ...   \n",
       "29981             0              1              0             0   \n",
       "29985             0              1              1             0   \n",
       "29989             0              1              0             0   \n",
       "29991             0              1              0             0   \n",
       "29992             1              0              1             0   \n",
       "\n",
       "       PU_is_downtown  DO_is_midtown  DO_is_uptown  DO_is_downtown  vendor_2  \\\n",
       "3                   0              0             0               0         0   \n",
       "4                   0              0             1               0         1   \n",
       "20                  0              1             0               0         1   \n",
       "22                  0              0             0               0         1   \n",
       "24                  1              0             0               1         1   \n",
       "...               ...            ...           ...             ...       ...   \n",
       "29981               0              0             0               0         1   \n",
       "29985               0              0             0               0         1   \n",
       "29989               0              0             0               0         0   \n",
       "29991               0              1             0               0         0   \n",
       "29992               1              1             0               0         1   \n",
       "\n",
       "       is_weekend  passenger_count  trip_distance  fare_amount     extra  \\\n",
       "3               1        -0.402384       3.189915     3.068634  0.502637   \n",
       "4               0         0.712355      -0.626034    -0.796223 -0.340178   \n",
       "20              0        -0.402384      -0.512801    -0.587795 -0.340178   \n",
       "22              1        -0.402384       3.214826     3.068634 -0.902054   \n",
       "24              0        -0.402384      -0.222925    -0.170938 -0.340178   \n",
       "...           ...              ...            ...          ...       ...   \n",
       "29981           0        -0.402384       2.141378     1.829974  2.469205   \n",
       "29985           1        -0.402384      -0.202543    -0.295995 -0.340178   \n",
       "29989           0        -0.402384       1.174369     0.954575  3.171550   \n",
       "29991           1        -0.402384       3.121975     3.068634  1.204983   \n",
       "29992           0         2.941833      -0.025900     0.287604  0.502637   \n",
       "\n",
       "       tolls_amount  improvement_surcharge  congestion_surcharge  airport_fee  \\\n",
       "3         -0.265522               0.040308              0.271461    -0.310566   \n",
       "4         -0.265522               0.040308              0.271461    -0.310566   \n",
       "20        -0.265522               0.040308              0.271461    -0.310566   \n",
       "22         3.078956               0.040308              0.271461    -0.310566   \n",
       "24        -0.265522               0.040308              0.271461    -0.310566   \n",
       "...             ...                    ...                   ...          ...   \n",
       "29981     -0.265522               0.040308             -3.683772     3.219929   \n",
       "29985     -0.265522               0.040308              0.271461    -0.310566   \n",
       "29989     -0.265522               0.040308             -3.683772     3.219929   \n",
       "29991      3.078956               0.040308              0.271461     3.219929   \n",
       "29992     -0.265522               0.040308              0.271461    -0.310566   \n",
       "\n",
       "       tip_amount  \n",
       "3             0.0  \n",
       "4             0.0  \n",
       "20            0.0  \n",
       "22            0.0  \n",
       "24            0.0  \n",
       "...           ...  \n",
       "29981         0.0  \n",
       "29985         0.0  \n",
       "29989         0.0  \n",
       "29991         0.0  \n",
       "29992         0.0  \n",
       "\n",
       "[6413 rows x 19 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"tip_amount\"]==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d80acf9-5e9a-41a7-a6e4-6ee7680d563b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='tip_amount', ylabel='Count'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Simulated Distribution of Tip Amount')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Tip Amount ($)')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Frequency')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 50.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.histplot(df[\"tip_amount\"], bins=100, kde=True, ax=ax, color='orange', edgecolor='black')\n",
    "\n",
    "ax.set_title('Simulated Distribution of Tip Amount', fontsize=14)\n",
    "ax.set_xlabel('Tip Amount ($)')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_xlim(0, 50)  # 裁剪右尾\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "130abba1-00a8-4617-ba42-4f28a8c2aecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\n",
    "    'is_peak_hour', 'is_night_hour', 'PU_is_midtown', 'PU_is_uptown',\n",
    "       'PU_is_downtown', 'DO_is_midtown', 'DO_is_uptown', 'DO_is_downtown',\n",
    "       'vendor_2', 'is_weekend', 'passenger_count', 'trip_distance',\n",
    "       'fare_amount', 'extra', 'tolls_amount', 'improvement_surcharge',\n",
    "       'congestion_surcharge', 'airport_fee', 'tip_amount'\n",
    "]\n",
    "\n",
    "target_col = 'tip_amount'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "ddc62bd4-f42b-4270-bce8-306cbd7df875",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3ded83f-7b44-494b-be00-bf3364b9d7ef",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d59e592-3be6-4860-a04c-91aa0e30381a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "0dc61b04-6bf0-4018-bd13-d94d7522ebde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df[target_col]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "c2cf2a0b-049a-4d99-9055-8f86fbb62506",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-94 {color: black;}#sk-container-id-94 pre{padding: 0;}#sk-container-id-94 div.sk-toggleable {background-color: white;}#sk-container-id-94 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-94 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-94 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-94 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-94 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-94 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-94 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-94 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-94 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-94 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-94 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-94 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-94 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-94 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-94 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-94 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-94 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-94 div.sk-item {position: relative;z-index: 1;}#sk-container-id-94 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-94 div.sk-item::before, #sk-container-id-94 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-94 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-94 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-94 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-94 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-94 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-94 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-94 div.sk-label-container {text-align: center;}#sk-container-id-94 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-94 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-94\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-94\" type=\"checkbox\" checked><label for=\"sk-estimator-id-94\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 2.8259\n",
      "Coefficient for trip_distance: -0.2923\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# 打印系数\n",
    "print(f\"Intercept: {model.intercept_:.4f}\")\n",
    "print(f\"Coefficient for trip_distance: {model.coef_[0]:.4f}\")\n",
    "\n",
    "# 可视化回归直线\n",
    "# plt.figure(figsize=(8, 5))\n",
    "# sns.scatterplot(x=X['fare_amount'], y=y, alpha=0.3)\n",
    "# plt.plot(X, model.predict(X), color='red', linewidth=2)\n",
    "# plt.xlabel(\"fare amount\")\n",
    "# plt.ylabel(\"Tip Amount\")\n",
    "# plt.title(\"Linear Regression: fare amount vs Tip\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "348b89b3-4128-4bd0-bd8c-73fca351d500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: 0.4076\n",
      "RMSE: 2.9426\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             tip_amount   R-squared:                       0.423\n",
      "Model:                            OLS   Adj. R-squared:                  0.423\n",
      "Method:                 Least Squares   F-statistic:                     1377.\n",
      "Date:                Fri, 18 Apr 2025   Prob (F-statistic):               0.00\n",
      "Time:                        21:42:26   Log-Likelihood:                -73850.\n",
      "No. Observations:               30000   AIC:                         1.477e+05\n",
      "Df Residuals:                   29983   BIC:                         1.479e+05\n",
      "Df Model:                          16                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "const                    2.8306      0.055     51.490      0.000       2.723       2.938\n",
      "is_peak_hour            -0.2642      0.062     -4.290      0.000      -0.385      -0.144\n",
      "is_night_hour           -0.0361      0.043     -0.847      0.397      -0.120       0.048\n",
      "PU_is_midtown            0.0273      0.039      0.695      0.487      -0.050       0.104\n",
      "PU_is_uptown             0.0908      0.058      1.574      0.116      -0.022       0.204\n",
      "PU_is_downtown           0.0044      0.045      0.098      0.922      -0.084       0.092\n",
      "DO_is_midtown           -0.0603      0.038     -1.587      0.113      -0.135       0.014\n",
      "DO_is_uptown             0.0357      0.049      0.727      0.467      -0.061       0.132\n",
      "DO_is_downtown           0.1113      0.042      2.633      0.008       0.028       0.194\n",
      "vendor_2                 0.8007      0.057     14.024      0.000       0.689       0.913\n",
      "is_weekend               0.0018      0.038      0.046      0.964      -0.074       0.077\n",
      "trip_distance            0.2064      0.065      3.172      0.002       0.079       0.334\n",
      "fare_amount              1.9132      0.060     31.916      0.000       1.796       2.031\n",
      "extra                    0.4935      0.032     15.520      0.000       0.431       0.556\n",
      "tolls_amount             0.3282      0.023     14.103      0.000       0.283       0.374\n",
      "congestion_surcharge     0.4815      0.020     23.996      0.000       0.442       0.521\n",
      "airport_fee              0.1337      0.029      4.594      0.000       0.077       0.191\n",
      "==============================================================================\n",
      "Omnibus:                    14813.299   Durbin-Watson:                   2.023\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          3111614.504\n",
      "Skew:                           1.248   Prob(JB):                         0.00\n",
      "Kurtosis:                      52.830   Cond. No.                         10.3\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(f\"R²: {r2_score(y_test, y_pred):.4f}\")\n",
    "print(f\"RMSE: {mean_squared_error(y_test, y_pred, squared=False):.4f}\")\n",
    "\n",
    "# statsmodels 显著性分析\n",
    "import statsmodels.api as sm\n",
    "X_sm = sm.add_constant(X)\n",
    "ols_model = sm.OLS(y, X_sm).fit()\n",
    "print(ols_model.summary())  # 查看 coef, p-value, R² 等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2089c7-7605-4c0b-86b9-2c7de7d97108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196408a2-bf2f-450a-92f1-41686dfd023e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94a894c9-137e-4eaa-869f-88f8fe030552",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Logist regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "8d85dd2b-fdaf-49f3-a07c-8a92ea3ea898",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: continuous. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[163], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m classification_report, roc_auc_score, confusion_matrix\n\u001b[1;32m      4\u001b[0m log_model \u001b[38;5;241m=\u001b[39m LogisticRegression(class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m'\u001b[39m, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mlog_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1216\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1206\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[1;32m   1208\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[1;32m   1209\u001b[0m     X,\n\u001b[1;32m   1210\u001b[0m     y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1214\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39msolver \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msag\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaga\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   1215\u001b[0m )\n\u001b[0;32m-> 1216\u001b[0m \u001b[43mcheck_classification_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n\u001b[1;32m   1219\u001b[0m multi_class \u001b[38;5;241m=\u001b[39m _check_multi_class(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulti_class, solver, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_))\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/utils/multiclass.py:216\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    208\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    215\u001b[0m ]:\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown label type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Maybe you are trying to fit a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier, which expects discrete classes on a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregression target with continuous values.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    220\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: continuous. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values."
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "\n",
    "log_model = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)\n",
    "log_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "faeab6b0-e4a1-4ef1-9872-2eae9ef43050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.6055\n",
      "R²: -1.1811\n",
      "AUC-ROC: 0.580297694397687\n",
      "Confusion Matrix:\n",
      " [[ 528  755]\n",
      " [1445 3272]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.41      0.32      1283\n",
      "           1       0.81      0.69      0.75      4717\n",
      "\n",
      "    accuracy                           0.63      6000\n",
      "   macro avg       0.54      0.55      0.54      6000\n",
      "weighted avg       0.70      0.63      0.66      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = log_model.predict(X_test)\n",
    "y_prob = log_model.predict_proba(X_test)[:, 1]  # 概率\n",
    "\n",
    "# 打印结果\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"R²: {r2:.4f}\")\n",
    "print(\"AUC-ROC:\", roc_auc_score(y_test, y_prob))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36673920-81d7-4063-bc72-77fdb5b7c285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50bf151-f0dc-4022-a013-34bd75ce6c33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f3b8eaa-fdf1-4518-ba1d-0d9f6409a9c7",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d601a9-8d4a-4ad5-9c0f-bdbbf9cd1f94",
   "metadata": {},
   "source": [
    "Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c605d02-e7f0-4d8f-a77d-397cb9c84a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model Result\n",
      "• RMSE: 1.0067\n",
      "• R² Score: 0.9254\n",
      "Training time: 0.24 seconds\n",
      "Prediction time: 0.01 seconds\n",
      "Total time: 0.25 seconds\n"
     ]
    }
   ],
   "source": [
    "# Data preparation\n",
    "X = df[feature_cols]\n",
    "y = df[target_col]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Model setup\n",
    "model = xgb.XGBRegressor(\n",
    "    objective='reg:squaredlogerror',\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "start_time_total = time.time()\n",
    "\n",
    "start_time_train = time.time()\n",
    "_ = model.fit(X_train, y_train)\n",
    "end_time_train = time.time()\n",
    "\n",
    "start_time_pred = time.time()\n",
    "y_pred = model.predict(X_test)\n",
    "end_time_pred = time.time()\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "end_time_total = time.time()\n",
    "\n",
    "print(f\"Baseline Model Result\")\n",
    "print(f\"• RMSE: {rmse:.4f}\")\n",
    "print(f\"• R² Score: {r2:.4f}\")\n",
    "print(f\"Training time: {end_time_train - start_time_train:.2f} seconds\")\n",
    "print(f\"Prediction time: {end_time_pred - start_time_pred:.2f} seconds\")\n",
    "print(f\"Total time: {end_time_total - start_time_total:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476a62da-fcb5-4427-92fa-69da387139dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44fcb7e-e32f-46bc-85c2-a42f9e8ea848",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3769d2b-8717-4352-86a4-52a720415b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=50,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
       "             num_parallel_tree=None, objective=&#x27;reg:squaredlogerror&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=50,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
       "             num_parallel_tree=None, objective=&#x27;reg:squaredlogerror&#x27;, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=50,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
       "             num_parallel_tree=None, objective='reg:squaredlogerror', ...)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model Result\n",
      "RMSE: 0.4991\n",
      "R² Score: 0.9817\n",
      "Training time: 2.32 seconds\n",
      "Prediction time: 0.06 seconds\n",
      "Total time: 2.38 seconds\n"
     ]
    }
   ],
   "source": [
    "# Create a small validation set (20% of X_test)\n",
    "X_val_small = X_test.sample(frac=0.2, random_state=42)\n",
    "y_val_small = y_test.loc[X_val_small.index]\n",
    "\n",
    "# Define the model\n",
    "model = xgb.XGBRegressor(\n",
    "    objective='reg:squaredlogerror',\n",
    "    n_estimators=1000,  # Large enough for early stopping\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    early_stopping_rounds=50,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Start profiling\n",
    "start_time_total = time.time()\n",
    "\n",
    "# Train the model\n",
    "start_time_train = time.time()\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val_small, y_val_small)],\n",
    "    verbose=False\n",
    ")\n",
    "end_time_train = time.time()\n",
    "\n",
    "# Predict on the full X_test\n",
    "start_time_pred = time.time()\n",
    "y_pred = model.predict(X_test)\n",
    "end_time_pred = time.time()\n",
    "\n",
    "# Evaluate\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "end_time_total = time.time()\n",
    "\n",
    "# Print results\n",
    "print(\"Baseline Model Result\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"R² Score: {r2:.4f}\")\n",
    "print(f\"Training time: {end_time_train - start_time_train:.2f} seconds\")\n",
    "print(f\"Prediction time: {end_time_pred - start_time_pred:.2f} seconds\")\n",
    "print(f\"Total time: {end_time_total - start_time_total:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b88d9c68-6167-4576-a85b-177f358b5491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.4991\n",
      "R²: 0.9817\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "# y_pred = np.expm1(y_pred_log)\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"R²: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "69891871-b7a6-4de1-a5f7-b03cdb25b60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2308     2.10\n",
       "22404    2.50\n",
       "23397    0.00\n",
       "25058    3.42\n",
       "2664     0.00\n",
       "         ... \n",
       "2210     3.08\n",
       "14144    3.00\n",
       "23108    2.00\n",
       "25703    4.90\n",
       "29171    2.94\n",
       "Name: tip_amount, Length: 6000, dtype: float64"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "86d66a73-e679-43f3-8f63-2df55fa28f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.7012813, 2.6152265, 3.7789328, ..., 1.7408371, 2.8496938,\n",
       "       2.3154483], dtype=float32)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "148ded2c-72f9-4fe7-b4dd-887d159842a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_peak_hour</th>\n",
       "      <th>is_night_hour</th>\n",
       "      <th>PU_is_midtown</th>\n",
       "      <th>PU_is_uptown</th>\n",
       "      <th>PU_is_downtown</th>\n",
       "      <th>DO_is_midtown</th>\n",
       "      <th>DO_is_uptown</th>\n",
       "      <th>DO_is_downtown</th>\n",
       "      <th>vendor_2</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>...</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tip_binary</th>\n",
       "      <th>log_tip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.161779</td>\n",
       "      <td>-0.254309</td>\n",
       "      <td>-0.902054</td>\n",
       "      <td>-0.265522</td>\n",
       "      <td>0.040308</td>\n",
       "      <td>0.271461</td>\n",
       "      <td>-0.310566</td>\n",
       "      <td>1.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1.036737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.370128</td>\n",
       "      <td>-0.379366</td>\n",
       "      <td>-0.340178</td>\n",
       "      <td>-0.265522</td>\n",
       "      <td>0.040308</td>\n",
       "      <td>0.271461</td>\n",
       "      <td>-0.310566</td>\n",
       "      <td>3.42</td>\n",
       "      <td>1</td>\n",
       "      <td>1.486140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.374657</td>\n",
       "      <td>-0.337681</td>\n",
       "      <td>0.502637</td>\n",
       "      <td>-0.265522</td>\n",
       "      <td>0.040308</td>\n",
       "      <td>0.271461</td>\n",
       "      <td>-0.310566</td>\n",
       "      <td>2.90</td>\n",
       "      <td>1</td>\n",
       "      <td>1.360977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.159515</td>\n",
       "      <td>-0.129252</td>\n",
       "      <td>-0.902054</td>\n",
       "      <td>-0.265522</td>\n",
       "      <td>0.040308</td>\n",
       "      <td>0.271461</td>\n",
       "      <td>-0.310566</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.299924</td>\n",
       "      <td>-0.295995</td>\n",
       "      <td>-0.902054</td>\n",
       "      <td>-0.265522</td>\n",
       "      <td>0.040308</td>\n",
       "      <td>0.271461</td>\n",
       "      <td>-0.310566</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1</td>\n",
       "      <td>1.682688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29994</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.763180</td>\n",
       "      <td>1.621546</td>\n",
       "      <td>1.064513</td>\n",
       "      <td>-0.265522</td>\n",
       "      <td>0.040308</td>\n",
       "      <td>0.271461</td>\n",
       "      <td>-0.310566</td>\n",
       "      <td>12.65</td>\n",
       "      <td>1</td>\n",
       "      <td>2.613740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.247836</td>\n",
       "      <td>-0.379366</td>\n",
       "      <td>-0.902054</td>\n",
       "      <td>-0.265522</td>\n",
       "      <td>0.040308</td>\n",
       "      <td>0.271461</td>\n",
       "      <td>-0.310566</td>\n",
       "      <td>3.22</td>\n",
       "      <td>1</td>\n",
       "      <td>1.439835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034959</td>\n",
       "      <td>0.162547</td>\n",
       "      <td>-0.902054</td>\n",
       "      <td>-0.265522</td>\n",
       "      <td>0.040308</td>\n",
       "      <td>0.271461</td>\n",
       "      <td>-0.310566</td>\n",
       "      <td>5.04</td>\n",
       "      <td>1</td>\n",
       "      <td>1.798404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.433538</td>\n",
       "      <td>-0.462738</td>\n",
       "      <td>-0.902054</td>\n",
       "      <td>-0.265522</td>\n",
       "      <td>0.040308</td>\n",
       "      <td>0.271461</td>\n",
       "      <td>-0.310566</td>\n",
       "      <td>2.94</td>\n",
       "      <td>1</td>\n",
       "      <td>1.371181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.528654</td>\n",
       "      <td>-0.629480</td>\n",
       "      <td>-0.902054</td>\n",
       "      <td>-0.265522</td>\n",
       "      <td>0.040308</td>\n",
       "      <td>0.271461</td>\n",
       "      <td>-0.310566</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23351 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       is_peak_hour  is_night_hour  PU_is_midtown  PU_is_uptown  \\\n",
       "0                 0              0              0             0   \n",
       "1                 0              1              0             1   \n",
       "2                 1              0              0             0   \n",
       "5                 0              0              0             1   \n",
       "6                 0              0              1             1   \n",
       "...             ...            ...            ...           ...   \n",
       "29994             0              1              1             0   \n",
       "29995             0              0              0             0   \n",
       "29996             0              0              0             0   \n",
       "29997             0              0              0             0   \n",
       "29998             0              0              0             0   \n",
       "\n",
       "       PU_is_downtown  DO_is_midtown  DO_is_uptown  DO_is_downtown  vendor_2  \\\n",
       "0                   0              0             0               1         1   \n",
       "1                   0              1             0               0         1   \n",
       "2                   1              0             0               0         1   \n",
       "5                   0              0             0               0         1   \n",
       "6                   0              0             0               1         1   \n",
       "...               ...            ...           ...             ...       ...   \n",
       "29994               0              0             0               0         0   \n",
       "29995               0              0             0               1         1   \n",
       "29996               1              1             0               0         1   \n",
       "29997               0              0             0               1         1   \n",
       "29998               1              0             0               0         1   \n",
       "\n",
       "       is_weekend  ...  trip_distance  fare_amount     extra  tolls_amount  \\\n",
       "0               1  ...      -0.161779    -0.254309 -0.902054     -0.265522   \n",
       "1               0  ...      -0.370128    -0.379366 -0.340178     -0.265522   \n",
       "2               0  ...      -0.374657    -0.337681  0.502637     -0.265522   \n",
       "5               0  ...      -0.159515    -0.129252 -0.902054     -0.265522   \n",
       "6               0  ...      -0.299924    -0.295995 -0.902054     -0.265522   \n",
       "...           ...  ...            ...          ...       ...           ...   \n",
       "29994           0  ...       1.763180     1.621546  1.064513     -0.265522   \n",
       "29995           0  ...      -0.247836    -0.379366 -0.902054     -0.265522   \n",
       "29996           0  ...      -0.034959     0.162547 -0.902054     -0.265522   \n",
       "29997           1  ...      -0.433538    -0.462738 -0.902054     -0.265522   \n",
       "29998           0  ...      -0.528654    -0.629480 -0.902054     -0.265522   \n",
       "\n",
       "       improvement_surcharge  congestion_surcharge  airport_fee  tip_amount  \\\n",
       "0                   0.040308              0.271461    -0.310566        1.82   \n",
       "1                   0.040308              0.271461    -0.310566        3.42   \n",
       "2                   0.040308              0.271461    -0.310566        2.90   \n",
       "5                   0.040308              0.271461    -0.310566        2.00   \n",
       "6                   0.040308              0.271461    -0.310566        4.38   \n",
       "...                      ...                   ...          ...         ...   \n",
       "29994               0.040308              0.271461    -0.310566       12.65   \n",
       "29995               0.040308              0.271461    -0.310566        3.22   \n",
       "29996               0.040308              0.271461    -0.310566        5.04   \n",
       "29997               0.040308              0.271461    -0.310566        2.94   \n",
       "29998               0.040308              0.271461    -0.310566        1.00   \n",
       "\n",
       "       tip_binary   log_tip  \n",
       "0               1  1.036737  \n",
       "1               1  1.486140  \n",
       "2               1  1.360977  \n",
       "5               1  1.098612  \n",
       "6               1  1.682688  \n",
       "...           ...       ...  \n",
       "29994           1  2.613740  \n",
       "29995           1  1.439835  \n",
       "29996           1  1.798404  \n",
       "29997           1  1.371181  \n",
       "29998           1  0.693147  \n",
       "\n",
       "[23351 rows x 21 columns]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = df[df[\"tip_amount\"]!=0]\n",
    "q = df_new[target_col].quantile(0.99)\n",
    "df_new = df_new[df_new[target_col] <= q]\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "a03e359a-d43b-47bf-a404-96448d86c3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_new[feature_cols]\n",
    "y = df_new[target_col]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train['fare_amount'] *= 3.0\n",
    "X_test['fare_amount'] *= 3.0\n",
    "\n",
    "max_depth_list = [4, 6, 8]\n",
    "learning_rate_list = [0.01, 0.02, 0.05, 0.1]\n",
    "n_estimators_list = [100, 250, 400]\n",
    "\n",
    "best_r2 = -np.inf\n",
    "best_params = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "28716e59-4f71-41d2-a32a-1c9aecccebf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absoluteerror | max_depth=4, lr=0.01, n_estimators=100 | RMSE=1.9426, R²=0.5952\n",
      "absoluteerror | max_depth=4, lr=0.01, n_estimators=250 | RMSE=1.6897, R²=0.6938\n",
      "absoluteerror | max_depth=4, lr=0.01, n_estimators=400 | RMSE=1.6748, R²=0.6992\n",
      "absoluteerror | max_depth=4, lr=0.02, n_estimators=100 | RMSE=1.7277, R²=0.6798\n",
      "absoluteerror | max_depth=4, lr=0.02, n_estimators=250 | RMSE=1.6839, R²=0.6959\n",
      "absoluteerror | max_depth=4, lr=0.02, n_estimators=400 | RMSE=1.7147, R²=0.6846\n",
      "absoluteerror | max_depth=4, lr=0.05, n_estimators=100 | RMSE=1.6865, R²=0.6949\n",
      "absoluteerror | max_depth=4, lr=0.05, n_estimators=250 | RMSE=1.7326, R²=0.6780\n",
      "absoluteerror | max_depth=4, lr=0.05, n_estimators=400 | RMSE=1.7432, R²=0.6741\n",
      "absoluteerror | max_depth=4, lr=0.1, n_estimators=100 | RMSE=1.7234, R²=0.6814\n",
      "absoluteerror | max_depth=4, lr=0.1, n_estimators=250 | RMSE=1.7445, R²=0.6736\n",
      "absoluteerror | max_depth=4, lr=0.1, n_estimators=400 | RMSE=1.7499, R²=0.6716\n",
      "absoluteerror | max_depth=6, lr=0.01, n_estimators=100 | RMSE=1.8926, R²=0.6158\n",
      "absoluteerror | max_depth=6, lr=0.01, n_estimators=250 | RMSE=1.6639, R²=0.7030\n",
      "absoluteerror | max_depth=6, lr=0.01, n_estimators=400 | RMSE=1.6652, R²=0.7026\n",
      "absoluteerror | max_depth=6, lr=0.02, n_estimators=100 | RMSE=1.6762, R²=0.6987\n",
      "absoluteerror | max_depth=6, lr=0.02, n_estimators=250 | RMSE=1.6827, R²=0.6963\n",
      "absoluteerror | max_depth=6, lr=0.02, n_estimators=400 | RMSE=1.7160, R²=0.6842\n",
      "absoluteerror | max_depth=6, lr=0.05, n_estimators=100 | RMSE=1.6856, R²=0.6953\n",
      "absoluteerror | max_depth=6, lr=0.05, n_estimators=250 | RMSE=1.7281, R²=0.6797\n",
      "absoluteerror | max_depth=6, lr=0.05, n_estimators=400 | RMSE=1.7384, R²=0.6759\n",
      "absoluteerror | max_depth=6, lr=0.1, n_estimators=100 | RMSE=1.7310, R²=0.6786\n",
      "absoluteerror | max_depth=6, lr=0.1, n_estimators=250 | RMSE=1.7421, R²=0.6745\n",
      "absoluteerror | max_depth=6, lr=0.1, n_estimators=400 | RMSE=1.7388, R²=0.6757\n",
      "absoluteerror | max_depth=8, lr=0.01, n_estimators=100 | RMSE=1.8664, R²=0.6264\n",
      "absoluteerror | max_depth=8, lr=0.01, n_estimators=250 | RMSE=1.6618, R²=0.7038\n",
      "absoluteerror | max_depth=8, lr=0.01, n_estimators=400 | RMSE=1.6778, R²=0.6981\n",
      "absoluteerror | max_depth=8, lr=0.02, n_estimators=100 | RMSE=1.6771, R²=0.6984\n",
      "absoluteerror | max_depth=8, lr=0.02, n_estimators=250 | RMSE=1.6994, R²=0.6902\n",
      "absoluteerror | max_depth=8, lr=0.02, n_estimators=400 | RMSE=1.7207, R²=0.6825\n",
      "absoluteerror | max_depth=8, lr=0.05, n_estimators=100 | RMSE=1.7030, R²=0.6890\n",
      "absoluteerror | max_depth=8, lr=0.05, n_estimators=250 | RMSE=1.7369, R²=0.6764\n",
      "absoluteerror | max_depth=8, lr=0.05, n_estimators=400 | RMSE=1.7434, R²=0.6740\n",
      "absoluteerror | max_depth=8, lr=0.1, n_estimators=100 | RMSE=1.7239, R²=0.6813\n",
      "absoluteerror | max_depth=8, lr=0.1, n_estimators=250 | RMSE=1.7340, R²=0.6775\n",
      "absoluteerror | max_depth=8, lr=0.1, n_estimators=400 | RMSE=1.7362, R²=0.6767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7038217790290651"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(8, 0.01, 250)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_r2 = -np.inf\n",
    "best_params = None\n",
    "\n",
    "for max_depth in max_depth_list:\n",
    "    for learning_rate in learning_rate_list:\n",
    "        for n_estimators in n_estimators_list:\n",
    "            model = xgb.XGBRegressor(\n",
    "                objective='reg:absoluteerror',\n",
    "                max_depth=max_depth,\n",
    "                learning_rate=learning_rate,\n",
    "                n_estimators=n_estimators,\n",
    "                random_state=42\n",
    "            )\n",
    "            _ = model.fit(X_train, y_train)\n",
    "            \n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "            print(f\"absoluteerror | max_depth={max_depth}, lr={learning_rate}, n_estimators={n_estimators} | RMSE={rmse:.4f}, R²={r2:.4f}\")\n",
    "\n",
    "            if r2 > best_r2:\n",
    "                best_r2 = r2\n",
    "                best_params = (max_depth, learning_rate, n_estimators)\n",
    "\n",
    "best_r2\n",
    "best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "1a37ea6f-3483-4cab-9254-1c43e3b81106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma | max_depth=4, lr=0.01, n_estimators=100 | RMSE=2.8327, R²=0.1394\n",
      "gamma | max_depth=4, lr=0.01, n_estimators=250 | RMSE=1.8841, R²=0.6193\n",
      "gamma | max_depth=4, lr=0.01, n_estimators=400 | RMSE=1.6418, R²=0.7109\n",
      "gamma | max_depth=4, lr=0.02, n_estimators=100 | RMSE=2.1165, R²=0.5196\n",
      "gamma | max_depth=4, lr=0.02, n_estimators=250 | RMSE=1.6251, R²=0.7168\n",
      "gamma | max_depth=4, lr=0.02, n_estimators=400 | RMSE=1.6233, R²=0.7174\n",
      "gamma | max_depth=4, lr=0.05, n_estimators=100 | RMSE=1.6262, R²=0.7164\n",
      "gamma | max_depth=4, lr=0.05, n_estimators=250 | RMSE=1.6320, R²=0.7143\n",
      "gamma | max_depth=4, lr=0.05, n_estimators=400 | RMSE=1.6315, R²=0.7145\n",
      "gamma | max_depth=4, lr=0.1, n_estimators=100 | RMSE=1.6259, R²=0.7165\n",
      "gamma | max_depth=4, lr=0.1, n_estimators=250 | RMSE=1.6390, R²=0.7119\n",
      "gamma | max_depth=4, lr=0.1, n_estimators=400 | RMSE=1.6659, R²=0.7024\n",
      "gamma | max_depth=6, lr=0.01, n_estimators=100 | RMSE=2.8320, R²=0.1398\n",
      "gamma | max_depth=6, lr=0.01, n_estimators=250 | RMSE=1.8849, R²=0.6190\n",
      "gamma | max_depth=6, lr=0.01, n_estimators=400 | RMSE=1.6530, R²=0.7070\n",
      "gamma | max_depth=6, lr=0.02, n_estimators=100 | RMSE=2.1148, R²=0.5203\n",
      "gamma | max_depth=6, lr=0.02, n_estimators=250 | RMSE=1.6427, R²=0.7106\n",
      "gamma | max_depth=6, lr=0.02, n_estimators=400 | RMSE=1.6548, R²=0.7063\n",
      "gamma | max_depth=6, lr=0.05, n_estimators=100 | RMSE=1.6398, R²=0.7116\n",
      "gamma | max_depth=6, lr=0.05, n_estimators=250 | RMSE=1.6549, R²=0.7063\n",
      "gamma | max_depth=6, lr=0.05, n_estimators=400 | RMSE=1.6641, R²=0.7030\n",
      "gamma | max_depth=6, lr=0.1, n_estimators=100 | RMSE=1.6609, R²=0.7041\n",
      "gamma | max_depth=6, lr=0.1, n_estimators=250 | RMSE=1.6949, R²=0.6919\n",
      "gamma | max_depth=6, lr=0.1, n_estimators=400 | RMSE=1.7277, R²=0.6799\n",
      "gamma | max_depth=8, lr=0.01, n_estimators=100 | RMSE=2.8341, R²=0.1385\n",
      "gamma | max_depth=8, lr=0.01, n_estimators=250 | RMSE=1.8915, R²=0.6163\n",
      "gamma | max_depth=8, lr=0.01, n_estimators=400 | RMSE=1.6677, R²=0.7017\n",
      "gamma | max_depth=8, lr=0.02, n_estimators=100 | RMSE=2.1196, R²=0.5182\n",
      "gamma | max_depth=8, lr=0.02, n_estimators=250 | RMSE=1.6653, R²=0.7026\n",
      "gamma | max_depth=8, lr=0.02, n_estimators=400 | RMSE=1.6820, R²=0.6966\n",
      "gamma | max_depth=8, lr=0.05, n_estimators=100 | RMSE=1.6686, R²=0.7014\n",
      "gamma | max_depth=8, lr=0.05, n_estimators=250 | RMSE=1.7012, R²=0.6896\n",
      "gamma | max_depth=8, lr=0.05, n_estimators=400 | RMSE=1.7242, R²=0.6811\n",
      "gamma | max_depth=8, lr=0.1, n_estimators=100 | RMSE=1.6930, R²=0.6926\n",
      "gamma | max_depth=8, lr=0.1, n_estimators=250 | RMSE=1.7383, R²=0.6759\n",
      "gamma | max_depth=8, lr=0.1, n_estimators=400 | RMSE=1.7979, R²=0.6533\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7173685066982743"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(4, 0.02, 400)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_r2 = -np.inf\n",
    "best_params = None\n",
    "\n",
    "for max_depth in max_depth_list:\n",
    "    for learning_rate in learning_rate_list:\n",
    "        for n_estimators in n_estimators_list:\n",
    "            model = xgb.XGBRegressor(\n",
    "                objective='reg:gamma',\n",
    "                max_depth=max_depth,\n",
    "                learning_rate=learning_rate,\n",
    "                n_estimators=n_estimators,\n",
    "                random_state=42\n",
    "            )\n",
    "            _ = model.fit(X_train, y_train)\n",
    "            \n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "            print(f\"gamma | max_depth={max_depth}, lr={learning_rate}, n_estimators={n_estimators} | RMSE={rmse:.4f}, R²={r2:.4f}\")\n",
    "\n",
    "            if r2 > best_r2:\n",
    "                best_r2 = r2\n",
    "                best_params = (max_depth, learning_rate, n_estimators)\n",
    "\n",
    "best_r2\n",
    "best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "51a4a4fa-1454-42f8-b9a8-48b0b34a883c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "squarederror | max_depth=4, lr=0.01, n_estimators=100 | RMSE=1.8769, R²=0.6222\n",
      "squarederror | max_depth=4, lr=0.01, n_estimators=250 | RMSE=1.6360, R²=0.7129\n",
      "squarederror | max_depth=4, lr=0.01, n_estimators=400 | RMSE=1.6280, R²=0.7158\n",
      "squarederror | max_depth=4, lr=0.02, n_estimators=100 | RMSE=1.6574, R²=0.7054\n",
      "squarederror | max_depth=4, lr=0.02, n_estimators=250 | RMSE=1.6317, R²=0.7145\n",
      "squarederror | max_depth=4, lr=0.02, n_estimators=400 | RMSE=1.6356, R²=0.7131\n",
      "squarederror | max_depth=4, lr=0.05, n_estimators=100 | RMSE=1.6333, R²=0.7139\n",
      "squarederror | max_depth=4, lr=0.05, n_estimators=250 | RMSE=1.6470, R²=0.7091\n",
      "squarederror | max_depth=4, lr=0.05, n_estimators=400 | RMSE=1.6642, R²=0.7029\n",
      "squarederror | max_depth=4, lr=0.1, n_estimators=100 | RMSE=1.6388, R²=0.7120\n",
      "squarederror | max_depth=4, lr=0.1, n_estimators=250 | RMSE=1.6768, R²=0.6984\n",
      "squarederror | max_depth=4, lr=0.1, n_estimators=400 | RMSE=1.6961, R²=0.6914\n",
      "squarederror | max_depth=6, lr=0.01, n_estimators=100 | RMSE=1.8690, R²=0.6254\n",
      "squarederror | max_depth=6, lr=0.01, n_estimators=250 | RMSE=1.6451, R²=0.7097\n",
      "squarederror | max_depth=6, lr=0.01, n_estimators=400 | RMSE=1.6445, R²=0.7100\n",
      "squarederror | max_depth=6, lr=0.02, n_estimators=100 | RMSE=1.6598, R²=0.7045\n",
      "squarederror | max_depth=6, lr=0.02, n_estimators=250 | RMSE=1.6540, R²=0.7066\n",
      "squarederror | max_depth=6, lr=0.02, n_estimators=400 | RMSE=1.6682, R²=0.7015\n",
      "squarederror | max_depth=6, lr=0.05, n_estimators=100 | RMSE=1.6541, R²=0.7066\n",
      "squarederror | max_depth=6, lr=0.05, n_estimators=250 | RMSE=1.6948, R²=0.6919\n",
      "squarederror | max_depth=6, lr=0.05, n_estimators=400 | RMSE=1.7164, R²=0.6840\n",
      "squarederror | max_depth=6, lr=0.1, n_estimators=100 | RMSE=1.6904, R²=0.6935\n",
      "squarederror | max_depth=6, lr=0.1, n_estimators=250 | RMSE=1.7352, R²=0.6771\n",
      "squarederror | max_depth=6, lr=0.1, n_estimators=400 | RMSE=1.7621, R²=0.6670\n",
      "squarederror | max_depth=8, lr=0.01, n_estimators=100 | RMSE=1.8742, R²=0.6232\n",
      "squarederror | max_depth=8, lr=0.01, n_estimators=250 | RMSE=1.6663, R²=0.7022\n",
      "squarederror | max_depth=8, lr=0.01, n_estimators=400 | RMSE=1.6776, R²=0.6982\n",
      "squarederror | max_depth=8, lr=0.02, n_estimators=100 | RMSE=1.6760, R²=0.6987\n",
      "squarederror | max_depth=8, lr=0.02, n_estimators=250 | RMSE=1.6881, R²=0.6944\n",
      "squarederror | max_depth=8, lr=0.02, n_estimators=400 | RMSE=1.7063, R²=0.6877\n",
      "squarederror | max_depth=8, lr=0.05, n_estimators=100 | RMSE=1.6892, R²=0.6940\n",
      "squarederror | max_depth=8, lr=0.05, n_estimators=250 | RMSE=1.7302, R²=0.6789\n",
      "squarederror | max_depth=8, lr=0.05, n_estimators=400 | RMSE=1.7611, R²=0.6674\n",
      "squarederror | max_depth=8, lr=0.1, n_estimators=100 | RMSE=1.7238, R²=0.6813\n",
      "squarederror | max_depth=8, lr=0.1, n_estimators=250 | RMSE=1.7859, R²=0.6579\n",
      "squarederror | max_depth=8, lr=0.1, n_estimators=400 | RMSE=1.8248, R²=0.6428\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7157500844400027"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(4, 0.01, 400)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_r2 = -np.inf\n",
    "best_params = None\n",
    "\n",
    "for max_depth in max_depth_list:\n",
    "    for learning_rate in learning_rate_list:\n",
    "        for n_estimators in n_estimators_list:\n",
    "            model = xgb.XGBRegressor(\n",
    "                objective='reg:squarederror',\n",
    "                max_depth=max_depth,\n",
    "                learning_rate=learning_rate,\n",
    "                n_estimators=n_estimators,\n",
    "                random_state=42\n",
    "            )\n",
    "            _ = model.fit(X_train, y_train)\n",
    "            \n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "            print(f\"squarederror | max_depth={max_depth}, lr={learning_rate}, n_estimators={n_estimators} | RMSE={rmse:.4f}, R²={r2:.4f}\")\n",
    "\n",
    "            if r2 > best_r2:\n",
    "                best_r2 = r2\n",
    "                best_params = (max_depth, learning_rate, n_estimators)\n",
    "\n",
    "\n",
    "best_r2\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "65fe4845-ff3f-48e2-ab25-1f42308331f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweedie | max_depth=4, lr=0.01, n_estimators=100 | RMSE=2.1272, R²=0.5147\n",
      "tweedie | max_depth=4, lr=0.01, n_estimators=250 | RMSE=1.6606, R²=0.7042\n",
      "tweedie | max_depth=4, lr=0.01, n_estimators=400 | RMSE=1.6253, R²=0.7167\n",
      "tweedie | max_depth=4, lr=0.02, n_estimators=100 | RMSE=1.7185, R²=0.6832\n",
      "tweedie | max_depth=4, lr=0.02, n_estimators=250 | RMSE=1.6258, R²=0.7165\n",
      "tweedie | max_depth=4, lr=0.02, n_estimators=400 | RMSE=1.6240, R²=0.7171\n",
      "tweedie | max_depth=4, lr=0.05, n_estimators=100 | RMSE=1.6221, R²=0.7178\n",
      "tweedie | max_depth=4, lr=0.05, n_estimators=250 | RMSE=1.6376, R²=0.7124\n",
      "tweedie | max_depth=4, lr=0.05, n_estimators=400 | RMSE=1.6518, R²=0.7074\n",
      "tweedie | max_depth=4, lr=0.1, n_estimators=100 | RMSE=1.6266, R²=0.7162\n",
      "tweedie | max_depth=4, lr=0.1, n_estimators=250 | RMSE=1.6577, R²=0.7053\n",
      "tweedie | max_depth=4, lr=0.1, n_estimators=400 | RMSE=1.6757, R²=0.6988\n",
      "tweedie | max_depth=6, lr=0.01, n_estimators=100 | RMSE=2.1229, R²=0.5167\n",
      "tweedie | max_depth=6, lr=0.01, n_estimators=250 | RMSE=1.6686, R²=0.7014\n",
      "tweedie | max_depth=6, lr=0.01, n_estimators=400 | RMSE=1.6463, R²=0.7093\n",
      "tweedie | max_depth=6, lr=0.02, n_estimators=100 | RMSE=1.7208, R²=0.6824\n",
      "tweedie | max_depth=6, lr=0.02, n_estimators=250 | RMSE=1.6500, R²=0.7080\n",
      "tweedie | max_depth=6, lr=0.02, n_estimators=400 | RMSE=1.6571, R²=0.7055\n",
      "tweedie | max_depth=6, lr=0.05, n_estimators=100 | RMSE=1.6512, R²=0.7076\n",
      "tweedie | max_depth=6, lr=0.05, n_estimators=250 | RMSE=1.6779, R²=0.6981\n",
      "tweedie | max_depth=6, lr=0.05, n_estimators=400 | RMSE=1.6966, R²=0.6913\n",
      "tweedie | max_depth=6, lr=0.1, n_estimators=100 | RMSE=1.6697, R²=0.7010\n",
      "tweedie | max_depth=6, lr=0.1, n_estimators=250 | RMSE=1.7164, R²=0.6840\n",
      "tweedie | max_depth=6, lr=0.1, n_estimators=400 | RMSE=1.7371, R²=0.6763\n",
      "tweedie | max_depth=8, lr=0.01, n_estimators=100 | RMSE=2.1262, R²=0.5151\n",
      "tweedie | max_depth=8, lr=0.01, n_estimators=250 | RMSE=1.6909, R²=0.6934\n",
      "tweedie | max_depth=8, lr=0.01, n_estimators=400 | RMSE=1.6861, R²=0.6951\n",
      "tweedie | max_depth=8, lr=0.02, n_estimators=100 | RMSE=1.7352, R²=0.6771\n",
      "tweedie | max_depth=8, lr=0.02, n_estimators=250 | RMSE=1.6891, R²=0.6940\n",
      "tweedie | max_depth=8, lr=0.02, n_estimators=400 | RMSE=1.7007, R²=0.6898\n",
      "tweedie | max_depth=8, lr=0.05, n_estimators=100 | RMSE=1.6963, R²=0.6914\n",
      "tweedie | max_depth=8, lr=0.05, n_estimators=250 | RMSE=1.7327, R²=0.6780\n",
      "tweedie | max_depth=8, lr=0.05, n_estimators=400 | RMSE=1.7633, R²=0.6665\n",
      "tweedie | max_depth=8, lr=0.1, n_estimators=100 | RMSE=1.7204, R²=0.6826\n",
      "tweedie | max_depth=8, lr=0.1, n_estimators=250 | RMSE=1.7798, R²=0.6603\n",
      "tweedie | max_depth=8, lr=0.1, n_estimators=400 | RMSE=1.8145, R²=0.6469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7177895448529008"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(4, 0.05, 100)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_r2 = -np.inf\n",
    "best_params = None\n",
    "\n",
    "for max_depth in max_depth_list:\n",
    "    for learning_rate in learning_rate_list:\n",
    "        for n_estimators in n_estimators_list:\n",
    "            model = xgb.XGBRegressor(\n",
    "                objective='reg:tweedie',\n",
    "                max_depth=max_depth,\n",
    "                learning_rate=learning_rate,\n",
    "                n_estimators=n_estimators,\n",
    "                tweedie_variance_power=1.5,  # 常用1.5，介于Poisson(1)和Gamma(2)之间\n",
    "                random_state=42\n",
    "            )\n",
    "            _ = model.fit(X_train, y_train)\n",
    "            \n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "            print(f\"tweedie | max_depth={max_depth}, lr={learning_rate}, n_estimators={n_estimators} | RMSE={rmse:.4f}, R²={r2:.4f}\")\n",
    "\n",
    "            if r2 > best_r2:\n",
    "                best_r2 = r2\n",
    "                best_params = (max_depth, learning_rate, n_estimators)\n",
    "\n",
    "best_r2\n",
    "best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "a914d0fe-e2d2-48c2-bd28-7a9db5cccebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "squaredlogerror | max_depth=4, lr=0.01, n_estimators=100 | RMSE=3.8854, R²=-0.6191\n",
      "squaredlogerror | max_depth=4, lr=0.01, n_estimators=250 | RMSE=2.7163, R²=0.2087\n",
      "squaredlogerror | max_depth=4, lr=0.01, n_estimators=400 | RMSE=1.9781, R²=0.5803\n",
      "squaredlogerror | max_depth=4, lr=0.02, n_estimators=100 | RMSE=3.0871, R²=-0.0222\n",
      "squaredlogerror | max_depth=4, lr=0.02, n_estimators=250 | RMSE=1.7834, R²=0.6589\n",
      "squaredlogerror | max_depth=4, lr=0.02, n_estimators=400 | RMSE=1.6675, R²=0.7018\n",
      "squaredlogerror | max_depth=4, lr=0.05, n_estimators=100 | RMSE=1.7829, R²=0.6591\n",
      "squaredlogerror | max_depth=4, lr=0.05, n_estimators=250 | RMSE=1.6604, R²=0.7043\n",
      "squaredlogerror | max_depth=4, lr=0.05, n_estimators=400 | RMSE=1.6634, R²=0.7032\n",
      "squaredlogerror | max_depth=4, lr=0.1, n_estimators=100 | RMSE=1.6616, R²=0.7039\n",
      "squaredlogerror | max_depth=4, lr=0.1, n_estimators=250 | RMSE=1.6674, R²=0.7018\n",
      "squaredlogerror | max_depth=4, lr=0.1, n_estimators=400 | RMSE=1.6742, R²=0.6994\n",
      "squaredlogerror | max_depth=6, lr=0.01, n_estimators=100 | RMSE=3.8853, R²=-0.6191\n",
      "squaredlogerror | max_depth=6, lr=0.01, n_estimators=250 | RMSE=2.7155, R²=0.2091\n",
      "squaredlogerror | max_depth=6, lr=0.01, n_estimators=400 | RMSE=1.9780, R²=0.5804\n",
      "squaredlogerror | max_depth=6, lr=0.02, n_estimators=100 | RMSE=3.0866, R²=-0.0218\n",
      "squaredlogerror | max_depth=6, lr=0.02, n_estimators=250 | RMSE=1.7844, R²=0.6585\n",
      "squaredlogerror | max_depth=6, lr=0.02, n_estimators=400 | RMSE=1.6723, R²=0.7001\n",
      "squaredlogerror | max_depth=6, lr=0.05, n_estimators=100 | RMSE=1.7844, R²=0.6585\n",
      "squaredlogerror | max_depth=6, lr=0.05, n_estimators=250 | RMSE=1.6666, R²=0.7021\n",
      "squaredlogerror | max_depth=6, lr=0.05, n_estimators=400 | RMSE=1.6705, R²=0.7007\n",
      "squaredlogerror | max_depth=6, lr=0.1, n_estimators=100 | RMSE=1.6696, R²=0.7010\n",
      "squaredlogerror | max_depth=6, lr=0.1, n_estimators=250 | RMSE=1.6761, R²=0.6987\n",
      "squaredlogerror | max_depth=6, lr=0.1, n_estimators=400 | RMSE=1.6862, R²=0.6951\n",
      "squaredlogerror | max_depth=8, lr=0.01, n_estimators=100 | RMSE=3.8853, R²=-0.6191\n",
      "squaredlogerror | max_depth=8, lr=0.01, n_estimators=250 | RMSE=2.7159, R²=0.2089\n",
      "squaredlogerror | max_depth=8, lr=0.01, n_estimators=400 | RMSE=1.9797, R²=0.5796\n",
      "squaredlogerror | max_depth=8, lr=0.02, n_estimators=100 | RMSE=3.0868, R²=-0.0219\n",
      "squaredlogerror | max_depth=8, lr=0.02, n_estimators=250 | RMSE=1.7877, R²=0.6572\n",
      "squaredlogerror | max_depth=8, lr=0.02, n_estimators=400 | RMSE=1.6759, R²=0.6988\n",
      "squaredlogerror | max_depth=8, lr=0.05, n_estimators=100 | RMSE=1.7878, R²=0.6572\n",
      "squaredlogerror | max_depth=8, lr=0.05, n_estimators=250 | RMSE=1.6700, R²=0.7009\n",
      "squaredlogerror | max_depth=8, lr=0.05, n_estimators=400 | RMSE=1.6784, R²=0.6979\n",
      "squaredlogerror | max_depth=8, lr=0.1, n_estimators=100 | RMSE=1.6701, R²=0.7008\n",
      "squaredlogerror | max_depth=8, lr=0.1, n_estimators=250 | RMSE=1.6813, R²=0.6968\n",
      "squaredlogerror | max_depth=8, lr=0.1, n_estimators=400 | RMSE=1.6975, R²=0.6909\n"
     ]
    }
   ],
   "source": [
    "best_r2 = -np.inf\n",
    "best_params = None\n",
    "\n",
    "for max_depth in max_depth_list:\n",
    "    for learning_rate in learning_rate_list:\n",
    "        for n_estimators in n_estimators_list:\n",
    "            model = xgb.XGBRegressor(\n",
    "                objective='reg:squaredlogerror',\n",
    "                max_depth=max_depth,\n",
    "                learning_rate=learning_rate,\n",
    "                n_estimators=n_estimators,\n",
    "                random_state=42\n",
    "            )\n",
    "            _ = model.fit(X_train, y_train)\n",
    "            \n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "            print(f\"squaredlogerror | max_depth={max_depth}, lr={learning_rate}, n_estimators={n_estimators} | RMSE={rmse:.4f}, R²={r2:.4f}\")\n",
    "\n",
    "            if r2 > best_r2:\n",
    "                best_r2 = r2\n",
    "                best_params = (max_depth, learning_rate, n_estimators)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "7b5630c4-c918-49cf-9e43-47be798352a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "squaredlogerror | max_depth=4, lr=0.01, n_estimators=100 | RMSE=3.8854, R²=-0.6191\n",
      "squaredlogerror | max_depth=4, lr=0.01, n_estimators=250 | RMSE=2.7163, R²=0.2087\n",
      "squaredlogerror | max_depth=4, lr=0.01, n_estimators=400 | RMSE=1.9781, R²=0.5803\n",
      "squaredlogerror | max_depth=4, lr=0.02, n_estimators=100 | RMSE=3.0871, R²=-0.0222\n",
      "squaredlogerror | max_depth=4, lr=0.02, n_estimators=250 | RMSE=1.7834, R²=0.6589\n",
      "squaredlogerror | max_depth=4, lr=0.02, n_estimators=400 | RMSE=1.6675, R²=0.7018\n",
      "squaredlogerror | max_depth=4, lr=0.05, n_estimators=100 | RMSE=1.7829, R²=0.6591\n",
      "squaredlogerror | max_depth=4, lr=0.05, n_estimators=250 | RMSE=1.6604, R²=0.7043\n",
      "squaredlogerror | max_depth=4, lr=0.05, n_estimators=400 | RMSE=1.6634, R²=0.7032\n",
      "squaredlogerror | max_depth=4, lr=0.1, n_estimators=100 | RMSE=1.6616, R²=0.7039\n",
      "squaredlogerror | max_depth=4, lr=0.1, n_estimators=250 | RMSE=1.6674, R²=0.7018\n",
      "squaredlogerror | max_depth=4, lr=0.1, n_estimators=400 | RMSE=1.6742, R²=0.6994\n",
      "squaredlogerror | max_depth=6, lr=0.01, n_estimators=100 | RMSE=3.8853, R²=-0.6191\n",
      "squaredlogerror | max_depth=6, lr=0.01, n_estimators=250 | RMSE=2.7155, R²=0.2091\n",
      "squaredlogerror | max_depth=6, lr=0.01, n_estimators=400 | RMSE=1.9780, R²=0.5804\n",
      "squaredlogerror | max_depth=6, lr=0.02, n_estimators=100 | RMSE=3.0866, R²=-0.0218\n",
      "squaredlogerror | max_depth=6, lr=0.02, n_estimators=250 | RMSE=1.7844, R²=0.6585\n",
      "squaredlogerror | max_depth=6, lr=0.02, n_estimators=400 | RMSE=1.6723, R²=0.7001\n",
      "squaredlogerror | max_depth=6, lr=0.05, n_estimators=100 | RMSE=1.7844, R²=0.6585\n",
      "squaredlogerror | max_depth=6, lr=0.05, n_estimators=250 | RMSE=1.6666, R²=0.7021\n",
      "squaredlogerror | max_depth=6, lr=0.05, n_estimators=400 | RMSE=1.6705, R²=0.7007\n",
      "squaredlogerror | max_depth=6, lr=0.1, n_estimators=100 | RMSE=1.6696, R²=0.7010\n",
      "squaredlogerror | max_depth=6, lr=0.1, n_estimators=250 | RMSE=1.6761, R²=0.6987\n",
      "squaredlogerror | max_depth=6, lr=0.1, n_estimators=400 | RMSE=1.6862, R²=0.6951\n",
      "squaredlogerror | max_depth=8, lr=0.01, n_estimators=100 | RMSE=3.8853, R²=-0.6191\n",
      "squaredlogerror | max_depth=8, lr=0.01, n_estimators=250 | RMSE=2.7159, R²=0.2089\n",
      "squaredlogerror | max_depth=8, lr=0.01, n_estimators=400 | RMSE=1.9797, R²=0.5796\n",
      "squaredlogerror | max_depth=8, lr=0.02, n_estimators=100 | RMSE=3.0868, R²=-0.0219\n",
      "squaredlogerror | max_depth=8, lr=0.02, n_estimators=250 | RMSE=1.7877, R²=0.6572\n",
      "squaredlogerror | max_depth=8, lr=0.02, n_estimators=400 | RMSE=1.6759, R²=0.6988\n",
      "squaredlogerror | max_depth=8, lr=0.05, n_estimators=100 | RMSE=1.7878, R²=0.6572\n",
      "squaredlogerror | max_depth=8, lr=0.05, n_estimators=250 | RMSE=1.6700, R²=0.7009\n",
      "squaredlogerror | max_depth=8, lr=0.05, n_estimators=400 | RMSE=1.6784, R²=0.6979\n",
      "squaredlogerror | max_depth=8, lr=0.1, n_estimators=100 | RMSE=1.6701, R²=0.7008\n",
      "squaredlogerror | max_depth=8, lr=0.1, n_estimators=250 | RMSE=1.6813, R²=0.6968\n",
      "squaredlogerror | max_depth=8, lr=0.1, n_estimators=400 | RMSE=1.6975, R²=0.6909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7043270048593568"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(4, 0.05, 250)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_r2 = -np.inf\n",
    "best_params = None\n",
    "\n",
    "for max_depth in max_depth_list:\n",
    "    for learning_rate in learning_rate_list:\n",
    "        for n_estimators in n_estimators_list:\n",
    "            model = xgb.XGBRegressor(\n",
    "                objective='reg:squaredlogerror',\n",
    "                max_depth=max_depth,\n",
    "                learning_rate=learning_rate,\n",
    "                n_estimators=n_estimators,\n",
    "                random_state=42\n",
    "            )\n",
    "            _ = model.fit(X_train, y_train)\n",
    "            \n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "            print(f\"squaredlogerror | max_depth={max_depth}, lr={learning_rate}, n_estimators={n_estimators} | RMSE={rmse:.4f}, R²={r2:.4f}\")\n",
    "\n",
    "            if r2 > best_r2:\n",
    "                best_r2 = r2\n",
    "                best_params = (max_depth, learning_rate, n_estimators)\n",
    "best_r2\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45294395-350d-4ba5-9559-8d3ab068b1d7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 换成log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "24c8420b-9985-49f6-bbd1-1ac635e6b781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-21 {color: black;}#sk-container-id-21 pre{padding: 0;}#sk-container-id-21 div.sk-toggleable {background-color: white;}#sk-container-id-21 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-21 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-21 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-21 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-21 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-21 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-21 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-21 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-21 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-21 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-21 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-21 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-21 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-21 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-21 div.sk-item {position: relative;z-index: 1;}#sk-container-id-21 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-21 div.sk-item::before, #sk-container-id-21 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-21 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-21 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-21 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-21 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-21 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-21 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-21 div.sk-label-container {text-align: center;}#sk-container-id-21 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-21 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-21\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.02, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=8, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=500, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" checked><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.02, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=8, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=500, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.02, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=8, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=500, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=42, ...)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_log = np.log1p(y_train)  # log(1 + y)\n",
    "y_test_log = np.log1p(y_test)\n",
    "\n",
    "model = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    n_estimators=500,     \n",
    "    max_depth=8,          \n",
    "    learning_rate=0.02, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d289c149-eb82-4285-ac77-7f8bc033628c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2.1428\n",
      "R²: 0.6605\n"
     ]
    }
   ],
   "source": [
    "y_pred_log = model.predict(X_test)\n",
    "y_pred = np.expm1(y_pred_log)\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"R²: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c904f8e0-845b-40de-b7a4-b60cb0996cb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
